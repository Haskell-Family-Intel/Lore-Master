# LorM: Lore Master – Structured Memory for Creative Intelligence

*Developed by Haskell Family Intel*

---

## 🧠 What Is LorM?
**LorM (Lore Master)** is a modular memory system designed to bring persistent, structured, and accurate recall to AI-enhanced storytelling.

It allows writers, worldbuilders, and LLM systems to maintain detailed continuity across massive narrative arcs — even beyond single sessions or token limits.

### Built For:
- 📚 Authors crafting complex story worlds
- 🎮 Game studios managing interactive lore bibles
- 🎥 Screenwriters tracking evolving timelines
- 🤖 LLM tool developers enhancing prompt consistency

---

## 🧬 What Makes LorM Unique?
Unlike traditional RAG systems, LorM emulates **human memory behavior**, with:

| Human Cognition       | LorM Equivalent                          |
|-----------------------|------------------------------------------|
| Hippocampus (STM)     | In-memory recall + current session cache |
| Long-Term Memory      | `LorMDB.json` archive with indexed schemas|
| Prefrontal Cortex     | `LorMRS.py` rule engine for active context |
| Memory Consolidation  | `LorMSM.py` cross-validation and update logic |
| Compression Heuristics| `AiQ-style` shorthand + hybrid storage |

It’s not just memory. It’s cognitive architecture.

---

## ⚙️ System Components
- `LorMDB.json` → Long-term structured lore memory
- `LorMIndex.json` → Shorthand compression + recall mapping
- `LorMRS.py` → RuleSet handler to determine what, when, and how to recall
- `LorMSM.py` → System monitor and integrity validator

Each narrative element — characters, places, events, relationships — is modular, compressible, and retrievable by name, type, or context.

---

## ✍️ How LorM Was Born
> *“I was just trying to keep my characters straight in a crossover fanfic.”*

LorM began as a necessity — a handcrafted memory scaffold for a crossover space opera where LLMs (Grok and ChatGPT) kept forgetting plot threads.

After manually building a shorthand memory system with persistent recall and compression, the author realized:  
🔁 *This wasn’t just for fiction. This was the missing layer in AI story reasoning.*

What began as a fanfiction patch became a full-fledged, narrative-aware memory framework — capable of reconstructing complex stories across time and models.

---

## 🚫 This Is Not Open Source
LorM is proprietary IP. It may not be:
- Forked
- Used for model training
- Republished
- Integrated into LLM infrastructure without a **paid license**

See [LICENSE.md](./LICENSE.md) for full legal terms.

---

## 💡 Why It Matters
Modern LLMs forget. They overwrite. They hallucinate.  
**But LorM remembers.**

You can:
- Feed a prompt with compressed backstory
- Maintain continuity across months of drafting
- Integrate structured narrative cards into any LLM-based tool

The result? An AI that *understands your world*, *remembers your characters*, and *builds on your lore* like a trusted co-author.

---

## 📁 Directory Overview
```
├── LICENSE.md            # Licensing details (strict commercial rules)
├── README.md             # This document
├── LorMDB.json           # Lore database (characters, arcs, events)
├── LorMIndex.json        # Indexed and compressed retrieval map
├── LorMRS.py             # RuleSet engine for context decision-making
├── LorMSM.py             # System monitor for validation and integrity
```

---

## 📬 Get in Touch
For licensing inquiries, private demos, or collaboration:
📧 haskellfamilyintel@protonmail.com

GitHub Home: [Haskell-Family-Intel](https://github.com/Haskell-Family-Intel)

---

**Build worlds that remember.**

**LorM is where your story lives.**
