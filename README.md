# LorM: Lore Master â€“ Structured Memory for Creative Intelligence

*Developed by Haskell Family Intel*

---

## ğŸ§  What Is LorM?
**LorM (Lore Master)** is a modular memory system designed to bring persistent, structured, and accurate recall to AI-enhanced storytelling.

It allows writers, worldbuilders, and LLM systems to maintain detailed continuity across massive narrative arcs â€” even beyond single sessions or token limits.

### Built For:
- ğŸ“š Authors crafting complex story worlds
- ğŸ® Game studios managing interactive lore bibles
- ğŸ¥ Screenwriters tracking evolving timelines
- ğŸ¤– LLM tool developers enhancing prompt consistency

---

## ğŸ§¬ What Makes LorM Unique?
Unlike traditional RAG systems, LorM emulates **human memory behavior**, with:

| Human Cognition       | LorM Equivalent                          |
|-----------------------|------------------------------------------|
| Hippocampus (STM)     | In-memory recall + current session cache |
| Long-Term Memory      | `LorMDB.json` archive with indexed schemas|
| Prefrontal Cortex     | `LorMRS.py` rule engine for active context |
| Memory Consolidation  | `LorMSM.py` cross-validation and update logic |
| Compression Heuristics| `AiQ-style` shorthand + hybrid storage |

Itâ€™s not just memory. Itâ€™s cognitive architecture.

---

## âš™ï¸ System Components
- `LorMDB.json` â†’ Long-term structured lore memory
- `LorMIndex.json` â†’ Shorthand compression + recall mapping
- `LorMRS.py` â†’ RuleSet handler to determine what, when, and how to recall
- `LorMSM.py` â†’ System monitor and integrity validator

Each narrative element â€” characters, places, events, relationships â€” is modular, compressible, and retrievable by name, type, or context.

---

## âœï¸ How LorM Was Born
> *â€œI was just trying to keep my characters straight in a crossover fanfic.â€*

LorM began as a necessity â€” a handcrafted memory scaffold for a crossover space opera where LLMs (Grok and ChatGPT) kept forgetting plot threads.

After manually building a shorthand memory system with persistent recall and compression, the author realized:  
ğŸ” *This wasnâ€™t just for fiction. This was the missing layer in AI story reasoning.*

What began as a fanfiction patch became a full-fledged, narrative-aware memory framework â€” capable of reconstructing complex stories across time and models.

---

## ğŸš« This Is Not Open Source
LorM is proprietary IP. It may not be:
- Forked
- Used for model training
- Republished
- Integrated into LLM infrastructure without a **paid license**

See [LICENSE.md](./LICENSE.md) for full legal terms.

---

## ğŸ’¡ Why It Matters
Modern LLMs forget. They overwrite. They hallucinate.  
**But LorM remembers.**

You can:
- Feed a prompt with compressed backstory
- Maintain continuity across months of drafting
- Integrate structured narrative cards into any LLM-based tool

The result? An AI that *understands your world*, *remembers your characters*, and *builds on your lore* like a trusted co-author.

---

## ğŸ“ Directory Overview
```
â”œâ”€â”€ LICENSE.md            # Licensing details (strict commercial rules)
â”œâ”€â”€ README.md             # This document
â”œâ”€â”€ LorMDB.json           # Lore database (characters, arcs, events)
â”œâ”€â”€ LorMIndex.json        # Indexed and compressed retrieval map
â”œâ”€â”€ LorMRS.py             # RuleSet engine for context decision-making
â”œâ”€â”€ LorMSM.py             # System monitor for validation and integrity
```

---

## ğŸ“¬ Get in Touch
For licensing inquiries, private demos, or collaboration:
ğŸ“§ haskellfamilyintel@protonmail.com

GitHub Home: [Haskell-Family-Intel](https://github.com/Haskell-Family-Intel)

---

**Build worlds that remember.**

**LorM is where your story lives.**
